{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import datetime\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, r'methods')\n",
    "\n",
    "from data_methods import getData, standardize\n",
    "# from dimensionality_reduction import reduce_dimensionality,reduce_with\n",
    "# from beamSearch import EMM, as_string\n",
    "# from adjPysubgroup import adjustedBestFirstSearch, adjustedDFS, adjustedApriori\n",
    "from qualityMeasures import calc_result_bs, calc_result_ps\n",
    "from interpretabilityMeasures import Feature_Correlation_Scores, DBI_beam, DBI_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the object using dill\n",
    "sd_results_path = r'C:\\Users\\20193723\\OneDrive - TU Eindhoven\\Documents\\Research Topics in Data Mining\\Interpretable-Subgroup-Discovery\\sd_results'\n",
    "file_name = 'Ionosphere-data-reductions.pkl'\n",
    "with open(os.path.join(sd_results_path,file_name), 'rb') as f:\n",
    "    loaded_dict =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = []\n",
    "# for dataset in dataset:\n",
    "#     file_name = '-data-reductions.pkl'\n",
    "#     en_methods = ['vanilla', 'auto_encoder', 'PCA', 'SPCA']\n",
    "#     for en_method in en_methods:\n",
    "#         fcs, fcss = Feature_Correlation_Scores(loaded_dict['vanilla'], loaded_dict[en_method])\n",
    "#         print(en_method, \"    \", \"\\n FCS: \", round(fcs, 2), \"    FCSS\", round(fcss, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder      \n",
      " FCS:  0.53     FCSS 0.13\n",
      "PCA      \n",
      " FCS:  0.65     FCSS 0.14\n",
      "SPCA      \n",
      " FCS:  0.72     FCSS 0.19\n"
     ]
    }
   ],
   "source": [
    "en_methods = ['auto_encoder', 'PCA', 'SPCA']\n",
    "for en_method in en_methods:\n",
    "    fcs, fcss = Feature_Correlation_Scores(loaded_dict['vanilla'], loaded_dict[en_method])\n",
    "    print(en_method, \"    \", \"\\n FCS: \", round(fcs, 2), \"    FCSS\", round(fcss, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loaded_dict['vanilla']\n",
    "df_en = loaded_dict['PCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_results_path = r'C:\\Users\\20193723\\OneDrive - TU Eindhoven\\Documents\\Research Topics in Data Mining\\Interpretable-Subgroup-Discovery\\sd_results'\n",
    "file_name = 'Ionosphere-results-24-10-2024-15-01.pkl'\n",
    "with open(os.path.join(sd_results_path,file_name), 'rb') as f:\n",
    "    loaded_dict =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs = loaded_dict['vanilla']['Best-First Search']['results_org']\n",
    "bfs_en = loaded_dict['PCA']['']['results_org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups_n = [i for i in beam_search.get_values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_sd_methods = ['Apriori', 'Best-First Search', 'Depth-First Search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=689, microseconds=623150)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict['vanilla']['Beam Search']['running_time_org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ionosphere :    \n",
      "\n",
      "auto_encoder :     \n",
      "   FCS:  0.53     FCSS 0.13\n",
      "DBI Apriori:  7.1264183629760245\n",
      "DBI Best-First Search:  6.055068569420404\n",
      "DBI Depth-First Search:  6.353466300390547\n",
      "DBI Beam Search:  1731120088263364.8 \n",
      "\n",
      "PCA :     \n",
      "   FCS:  0.65     FCSS 0.14\n",
      "DBI Apriori:  7.308475820444398\n",
      "DBI Best-First Search:  6.663956085266635\n",
      "DBI Depth-First Search:  6.632011546952284\n",
      "DBI Beam Search:  1.5491901587864972e+16 \n",
      "\n",
      "SPCA :     \n",
      "   FCS:  0.72     FCSS 0.19\n",
      "DBI Apriori:  7.088910353666094\n",
      "DBI Best-First Search:  7.172361791274352\n",
      "DBI Depth-First Search:  7.106983731853952\n",
      "DBI Beam Search:  8756581801206236.0 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dct_datasets = ['Ionosphere'] # to test <- Remove later\n",
    "for dataset in dct_datasets:\n",
    "    df_file_name = dataset+'-data-reductions.pkl'\n",
    "    results_file_name = dataset+'-results-24-10-2024-15-01.pkl'\n",
    "    with open(os.path.join(sd_results_path,df_file_name), 'rb') as f:\n",
    "        dfs_dict =pickle.load(f)\n",
    "    with open(os.path.join(sd_results_path,results_file_name), 'rb') as f:\n",
    "        results_dict =pickle.load(f)\n",
    "    print(dataset, \":    \\n\")\n",
    "    en_methods = ['auto_encoder', 'PCA', 'SPCA']\n",
    "    ps_sd_methods = ['Apriori', 'Best-First Search', 'Depth-First Search']\n",
    "    for en_method in en_methods:\n",
    "        fcs, fcss = Feature_Correlation_Scores(dfs_dict['vanilla'], dfs_dict[en_method])\n",
    "        print(en_method, \":    \", \"\\n   FCS: \", round(fcs, 2), \"    FCSS\", round(fcss, 2))\n",
    "        for sd_method in ps_sd_methods:\n",
    "            dbi = DBI_ps(results_dict[en_method][sd_method]['results_org'], dfs_dict[en_method])\n",
    "            print(\"DBI \"+sd_method+\": \", dbi)\n",
    "        subgroups_beam = [i for i in results_dict[en_method]['Beam Search']['results_org'].get_values()]\n",
    "        dbi = DBI_beam(subgroups_beam, dfs_dict[en_method])\n",
    "        print(\"DBI Beam Search: \", dbi, \"\\n\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-First Search\n",
      "Depth-First Search\n",
      "Apriori\n",
      "Beam Search\n"
     ]
    }
   ],
   "source": [
    "for i in loaded_dict['vanilla']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_en \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20193723\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\20193723\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20193723\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\20193723\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "df_en = pd.DataFrame(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
