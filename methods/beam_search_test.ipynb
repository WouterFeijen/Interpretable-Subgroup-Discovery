{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# open data\n",
    "# Fix beam search algorithm\n",
    "# run beam search\n",
    "# run results code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import sys\n",
    "# import logging\n",
    "# import datetime\n",
    "import dill as pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original py files\n",
    "# sys.path.insert(1, 'methods')\n",
    "\n",
    "from data_methods import getData, standardize\n",
    "from dimensionality_reduction import reduce_dimensionality,reduce_with\n",
    "from beamSearch import EMM, as_string\n",
    "from adjPysubgroup import adjustedBestFirstSearch, adjustedDFS, adjustedApriori\n",
    "from qualityMeasures import calc_result_bs, calc_result_ps\n",
    "from interpretabilityMeasures import Feature_Correlation_Scores, DBI_beam, DBI_ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_datasets = {}\n",
    "\n",
    "for dataset in ['Ionosphere','Mushroom','Adult','Soybean','Arrhythmia','Indoor']:\n",
    "\n",
    "    with open(os.path.join(\n",
    "        r'W:\\OneDrive - TU Eindhoven\\DS&AI\\2024-2025\\2024-2025 q1\\2AMM20 - Research Topics in Data Mining\\Research Project Phase\\GitHub Code\\Interpretable-Subgroup-Discovery-1\\results_renamed',\n",
    "        f'{dataset}-data-reductions.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    dct_datasets[dataset] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problem 1: </b> ```eta``` function generates all possible refinements of a seed by adding new conditions based on all features, regardless of whether a feature is already used in the seed; it does not prevent the addition of new conditions on attributes that are already used in the seed. Thus, seeds with a certain attribute can be refined by adding another condition that includes the same attribute.<br>\n",
    "<b>Solution:</b> modify the ```eta``` function so that it is only possible to refine a seed using attributes that are not already present in the seed.\n",
    "\n",
    "\n",
    "<b>Problem 2:</b> The current Beam Search algorithm does not check whether subgroups with similar conditions contain the same subgroups, e.g. attr1 <= 5 AND attr2 > 3 might select the same observations as attr1 <= 5 AND attr2 >= 4. This results in duplicate subgroups, defined by fairly similar rules. <br>\n",
    "<b>Solution:</b> Check for subgroup equivalence before adding a new subgroup to the result set to verify whether it is unique in its observations\n",
    "<br>\n",
    "\n",
    "#### Finished code:\n",
    "```python\n",
    "Fixed code with comments\n",
    "\"\"\"\n",
    "The following code was adapted from W. Duivesteijn, T.C. van Dijk. (2021)\n",
    "    Exceptional Gestalt Mining: Combining Magic Cards to Make Complex Coalitions Thrive. \n",
    "    In: Proceedings of the 8th Workshop on Machine Learning and Data Mining for Sports Analytics.\n",
    "    Available from http://wwwis.win.tue.nl/~wouter/Publ/J05-EMM_DMKD.pdf\n",
    "\"\"\"\n",
    "\n",
    "# Package imports\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "# Classes\n",
    "class BoundedPriorityQueue:\n",
    "    \"\"\"\n",
    "    Used to store the <q> most promising subgroups\n",
    "    Ensures uniqness\n",
    "    Keeps a maximum size (throws away value with least quality)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bound): \n",
    "        # Initializes empty queue with maximum length of <bound>\n",
    "        self.values = []\n",
    "        self.bound = bound\n",
    "        self.entry_count = 0\n",
    "\n",
    "    def add(self, element, quality, **adds): \n",
    "        # Adds <element> to the bounded priority queue if it is of sufficient quality\n",
    "        new_entry = (quality, self.entry_count, element, adds)\n",
    "        if (len(self.values) >= self.bound):\n",
    "            heapq.heappushpop(self.values, new_entry)\n",
    "        else:\n",
    "            heapq.heappush(self.values, new_entry)\n",
    "\n",
    "        self.entry_count += 1\n",
    "\n",
    "    def get_values(self):\n",
    "        # Returns elements in bounded priority queue in sorted order\n",
    "        for (q, _, e, x) in sorted(self.values, reverse=True):\n",
    "            yield (q, e, x)\n",
    "\n",
    "    def show_contents(self):  \n",
    "        # Prints contents of the bounded priority queue (used for debugging)\n",
    "        print(\"show_contents\")\n",
    "        for (q, entry_count, e) in self.values:\n",
    "            print(q, entry_count, e)\n",
    "\n",
    "class Queue:\n",
    "    \"\"\"\n",
    "    Used to store candidate solutions\n",
    "    Ensures uniqness\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self): # Initializes empty queue\n",
    "        self.items = []\n",
    "\n",
    "    def is_empty(self): # Returns True if queue is empty, False otherwise\n",
    "        return self.items == []\n",
    "\n",
    "    def enqueue(self, item): # Adds <item> to queue if it is not already present\n",
    "        if item not in self.items:\n",
    "            self.items.insert(0, item)\n",
    "\n",
    "    def dequeue(self): # Pulls one item from the queue\n",
    "        return self.items.pop()\n",
    "\n",
    "    def size(self): # Returns the number of items in the queue\n",
    "        return len(self.items)\n",
    "\n",
    "    def get_values(self): # Returns the queue (as a list)\n",
    "        return self.items\n",
    "\n",
    "    def add_all(self, iterable): # Adds all items in <iterable> to the queue, given they are not already present\n",
    "        for item in iterable:\n",
    "            self.enqueue(item)\n",
    "\n",
    "    def clear(self): # Removes all items from the queue\n",
    "        self.items.clear()\n",
    "        \n",
    "# Functions\n",
    "def refine(desc, more):\n",
    "    # Creates a copy of the seed <desc> and adds it to the new selector <more>\n",
    "    # Used to prevent pointer issues with selectors\n",
    "    copy = desc[:]\n",
    "    copy.append(more)\n",
    "    return copy\n",
    "\n",
    "def as_string(desc):\n",
    "    # Adds ' and ' to <desc> such that selectors are properly separated when the refine function is used\n",
    "    return ' and '.join(desc)\n",
    "\n",
    "def eta(seed, df, features, n_chunks = 5,prnt=False):\n",
    "    # Returns a generator which includes all possible refinements of <seed> for the given <features> on dataset <df>\n",
    "    # n_chunks refers to the number of possible splits we consider for numerical features\n",
    "    if prnt:\n",
    "        print(\"eta \", seed)\n",
    "\n",
    "    # ! Find features present in the current seed and exclude them from the possible features:\n",
    "    # ! -> function currently only checks whether the condition is already in there, allowing for different conditions on the same attributes\n",
    "    used_features = set()\n",
    "    for condition in seed:\n",
    "        feature_name = condition.split()[0]\n",
    "        used_features.add(feature_name)\n",
    "    available_features = [f for f in features if f not in used_features]\n",
    "    # ! end of adjusted code\n",
    "\n",
    "    # only specify more on the elements that are still in the subset\n",
    "    if seed != []:              \n",
    "        d_str = as_string(seed)\n",
    "        ind = df.eval(d_str)\n",
    "        df_sub = df.loc[ind, ]\n",
    "    else:\n",
    "        df_sub = df\n",
    "\n",
    "    for f in available_features:\n",
    "        # if (df_sub[f].dtype == 'float64') or (df_sub[f].dtype == 'float32'): #get quantiles here instead of intervals for the case that data are very skewed\n",
    "        if pd.api.types.is_numeric_dtype(df_sub[f]): # ! more reliable than comparing it to a float as .dtype returns an object and not a string\n",
    "            column_data = df_sub[f]\n",
    "            dat = np.sort(column_data)\n",
    "            dat = dat[np.logical_not(np.isnan(dat))]\n",
    "            for i in range(1,n_chunks+1): #determine the number of chunks you want to divide your data in\n",
    "                x = np.percentile(dat, 100 * i / n_chunks) # ! changed from 100 / i which is INCORRECT\n",
    "                candidate_leq = f\"{f} <= {x}\" # ! changed from .format to fstring\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_leq)\n",
    "                candidate_gt = f\"{f} > {x}\"\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_gt)\n",
    "        # elif (df_sub[f].dtype == 'object'):\n",
    "        elif pd.api.types.is_categorical_dtype(df_sub[f]) or pd.api.types.is_object_dtype(df_sub[f]): # ! more reliable\n",
    "            column_data = df_sub[f]\n",
    "            uniq = column_data.dropna().unique()\n",
    "            for i in uniq:\n",
    "                candidate_eq = f\"{f} == '{i}'\"\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_eq)\n",
    "                candidate_neq = f\"{f} != '{i}'\"\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_neq)\n",
    "        # elif (df_sub[f].dtype == 'int64'):\n",
    "        #     column_data = df_sub[f]\n",
    "        #     dat = np.sort(column_data)\n",
    "        #     dat = dat[np.logical_not(np.isnan(dat))]\n",
    "        #     for i in range(1,n_chunks+1): #determine the number of chunks you want to divide your data in\n",
    "        #         x = np.percentile(dat,100/i) #\n",
    "        #         candidate = \"{} <= {}\".format(f, x)\n",
    "        #         # if not candidate in seed: # if not already there\n",
    "        #         yield refine(seed, candidate)\n",
    "        #         candidate = \"{} > {}\".format(f, x)\n",
    "        #         # if not candidate in seed: # if not already there\n",
    "        #         yield refine(seed, candidate)\n",
    "        # elif (df_sub[f].dtype == 'bool'):\n",
    "        elif pd.api.types.is_bool_dtype(df_sub[f]): # ! more reliable\n",
    "            # uniq = column_data.dropna().unique()\n",
    "            for i in [True,False]: # ! instead of unique\n",
    "                candidate_eq = f\"{f} == '{i}'\"\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_eq)\n",
    "                candidate_neq = f\"{f} != '{i}'\"\n",
    "                # if not candidate in seed: # if not already there\n",
    "                yield refine(seed, candidate_neq)\n",
    "        else:\n",
    "            # assert False\n",
    "            continue # ! skip for unsupported dtypes\n",
    "\n",
    "def satisfies_all(desc, df, threshold=0.02):\n",
    "    # Function used to check if subgroup with pattern <desc> is sufficiently big relative to its dataset <df>\n",
    "    # A subgroup is sufficiently big if the proportion of data included in it exceeds <threshold>   \n",
    "    d_str = as_string(desc)\n",
    "    ind = df.eval(d_str)\n",
    "    return sum(ind) >= len(df) * 0.02 \n",
    "\n",
    "def eval_quality(desc, df, target):\n",
    "    # Function used to calculate the solution's WRAcc\n",
    "    sub_group = df[df.eval(as_string(desc))] \n",
    "    prop_p_sg = len(sub_group[sub_group[target]==1])/len(sub_group)\n",
    "    prop_p_df = len(df[df[target]==1])/len(df)\n",
    "    wracc = ((len(sub_group)/len(df))**1) * (prop_p_sg - prop_p_df) #for WRAcc a=1\n",
    "    return wracc\n",
    "\n",
    "\n",
    "\n",
    "def EMM(w, d, q, catch_all_description, df, target, n_chunks=5, ensure_diversity = False,prnt_level=True,prnt_seed=True,prnt_eta=False):\n",
    "    \"\"\"\n",
    "    w - width of beam, i.e. the max number of results in the beam\n",
    "    d - num levels, i.e. how many attributes are considered\n",
    "    q - max results, i.e. max number of results output by the algorithm\n",
    "    eta - a function that receives a description and returns all possible refinements\n",
    "    satisfies_all - a function that receives a description and verifies wheather it satisfies some requirements as needed\n",
    "    eval_quality - returns a quality for a given description. This should be comparable to qualities of other descriptions\n",
    "    catch_all_description - the equivalent of True, or all, as that the whole dataset shall match\n",
    "    df - dataframe of mined dataset\n",
    "    features - features in scope\n",
    "    target - column name of target attribute in df\n",
    "    \"\"\"\n",
    "    features = [col for col in df.columns if col!='target']\n",
    "    \n",
    "    # Initialize variables\n",
    "    resultSet = BoundedPriorityQueue(q) # Set of results, can contain results from multiple levels\n",
    "    candidateQueue = Queue() # Set of candidate solutions to consider adding to the ResultSet\n",
    "    candidateQueue.enqueue(catch_all_description) # Set of results on a particular level\n",
    "    error = 0.00001 # Allowed error margin (due to floating point error) when comparing the quality of solutions\n",
    "\n",
    "    # ! keep track of seen_subgroups:\n",
    "    seen_subgroups = set()\n",
    "\n",
    "    # Perform BeamSearch for <d> levels\n",
    "    for level in range(d):\n",
    "        if prnt_level:\n",
    "            print(\"level : \", level)\n",
    "        \n",
    "        # Initialize this level's beam\n",
    "        beam = BoundedPriorityQueue(w)\n",
    "\n",
    "        # Go over all rules generated on previous level, or 'empty' rule if level = 0 \n",
    "        for seed in candidateQueue.get_values():\n",
    "            if prnt_seed:\n",
    "                print(\"    seed : \", seed)\n",
    "            \n",
    "            # Start by evaluating the quality of the seed\n",
    "            if seed != []:\n",
    "                seed_quality = eval_quality(seed, df, target)\n",
    "                beam.add(seed, seed_quality) # ! include seed itself in the beam\n",
    "            else:\n",
    "                seed_quality = float('-inf') # instead of 99\n",
    "\n",
    "            # For all refinements created by eta function on descriptions (i.e features), which can be different types of columns\n",
    "            # eta(seed) reads the dataset given certain seed (i.e. already created rules) and looks at new descriptions\n",
    "            for desc in eta(seed, df, features, n_chunks,prnt=prnt_eta):\n",
    "\n",
    "                # Check if the subgroup contains at least x% of data, proceed if yes\n",
    "                if satisfies_all(desc, df):\n",
    "                    # generate hash of subgroup indices\n",
    "                    subgroup_indices = df[df.eval(as_string(desc))].index\n",
    "                    subgroup_hash = tuple(sorted(subgroup_indices))\n",
    "\n",
    "                    # skip if the (hash of the) subgroup has already been visited\n",
    "                    if subgroup_hash in seen_subgroups:\n",
    "                        continue\n",
    "                    # if it has not been seen, we continue and add the new hash to the set\n",
    "                    seen_subgroups.add(subgroup_hash)\n",
    "\n",
    "                    # Calculate the new solution's quality\n",
    "                    quality = eval_quality(desc, df, target)\n",
    "                    \n",
    "                    # Ensure diversity by forcing difference in quality when compared to its seed\n",
    "                    # if <ensure_diversity> is set to True. Principle is based on:\n",
    "                    # Van Leeuwen, M., & Knobbe, A. (2012), Diverse subgroup set discovery.\n",
    "                    # Data Mining and Knowledge Discovery, 25(2), 208-242.\n",
    "                    if ensure_diversity:\n",
    "                        # if quality < (seed_quality * 1-error) or quality > (seed_quality * 1+error) : # ! <- irrelevantly long condition\n",
    "                        if abs(quality - seed_quality) > error:\n",
    "                            resultSet.add(desc, quality)\n",
    "                            beam.add(desc, quality)\n",
    "                    else:\n",
    "                        resultSet.add(desc, quality)\n",
    "                        beam.add(desc, quality)\n",
    "\n",
    "        # When all candidates for a search level have been explored, \n",
    "        # the contents of the beam are moved into candidateQueue, to generate next level candidates\n",
    "        candidateQueue = Queue()\n",
    "        candidateQueue.add_all(desc for (_, desc, _) in beam.get_values())\n",
    "        \n",
    "    # Return the <resultSet> once the BeamSearch algorithm has completed\n",
    "    return resultSet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Beam Search algo's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level :  0\n",
      "    seed :  []\n",
      "level :  1\n",
      "    seed :  [\"attribute10 != '0'\"]\n",
      "    seed :  [\"attribute14 == '1'\"]\n",
      "    seed :  [\"attribute34 != '0'\"]\n",
      "    seed :  [\"attribute2 != '0'\"]\n",
      "    seed :  [\"attribute1 == '0'\"]\n",
      "    seed :  [\"attribute28 != '1'\"]\n",
      "    seed :  [\"attribute35 != '0'\"]\n",
      "    seed :  [\"attribute7 == '2'\"]\n",
      "    seed :  [\"attribute22 == '1'\"]\n",
      "    seed :  [\"attribute1 == '3'\"]\n",
      "    seed :  [\"attribute23 == '1'\"]\n",
      "    seed :  [\"attribute24 == '1'\"]\n",
      "    seed :  [\"attribute6 == '0'\"]\n",
      "    seed :  [\"attribute1 == '6'\"]\n",
      "    seed :  [\"attribute1 != '2'\"]\n",
      "    seed :  [\"attribute6 == '2'\"]\n",
      "    seed :  [\"attribute9 == '1'\"]\n",
      "    seed :  [\"attribute10 != '2'\"]\n",
      "    seed :  [\"attribute3 != '1'\"]\n",
      "    seed :  [\"attribute17 != '0'\"]\n",
      "    seed :  [\"attribute1 == '4'\"]\n",
      "    seed :  [\"attribute1 != '1'\"]\n",
      "    seed :  [\"attribute1 == '1'\"]\n",
      "    seed :  [\"attribute1 != '4'\"]\n",
      "    seed :  [\"attribute17 == '0'\"]\n",
      "    seed :  [\"attribute3 == '1'\"]\n",
      "    seed :  [\"attribute10 == '2'\"]\n",
      "    seed :  [\"attribute35 != '2'\"]\n",
      "    seed :  [\"attribute9 != '1'\"]\n",
      "    seed :  [\"attribute25 == '0'\"]\n",
      "    seed :  [\"attribute6 != '2'\"]\n",
      "    seed :  [\"attribute1 == '2'\"]\n",
      "    seed :  [\"attribute1 != '6'\"]\n",
      "    seed :  [\"attribute6 != '0'\"]\n",
      "    seed :  [\"attribute24 != '1'\"]\n",
      "    seed :  [\"attribute35 != '1'\"]\n",
      "    seed :  [\"attribute1 != '3'\"]\n",
      "    seed :  [\"attribute23 != '1'\"]\n",
      "    seed :  [\"attribute22 != '1'\"]\n",
      "    seed :  [\"attribute7 != '2'\"]\n",
      "    seed :  [\"attribute35 == '0'\"]\n",
      "    seed :  [\"attribute28 == '1'\"]\n",
      "    seed :  [\"attribute1 != '0'\"]\n",
      "    seed :  [\"attribute2 == '0'\"]\n",
      "    seed :  [\"attribute34 == '0'\"]\n",
      "    seed :  [\"attribute14 != '1'\"]\n",
      "    seed :  [\"attribute10 == '0'\"]\n",
      "    seed :  [\"attribute9 != '0'\"]\n",
      "    seed :  [\"attribute7 != '0'\"]\n",
      "    seed :  [\"attribute8 != '1'\"]\n",
      "    seed :  [\"attribute18 != '1'\"]\n",
      "    seed :  [\"attribute18 != '2'\"]\n",
      "    seed :  [\"attribute21 != '2'\"]\n",
      "    seed :  [\"attribute26 != '2'\"]\n",
      "    seed :  [\"attribute10 != '1'\"]\n",
      "    seed :  [\"attribute22 != '2'\"]\n",
      "    seed :  [\"attribute9 == '2'\"]\n",
      "    seed :  [\"attribute21 == '3'\"]\n",
      "    seed :  [\"attribute6 != '1'\"]\n",
      "    seed :  [\"attribute4 == '1'\"]\n",
      "    seed :  [\"attribute1 == '5'\"]\n",
      "    seed :  [\"attribute33 == '0'\"]\n",
      "    seed :  [\"attribute29 != '2'\"]\n",
      "    seed :  [\"attribute7 != '1'\"]\n",
      "    seed :  [\"attribute32 == '0'\"]\n",
      "    seed :  [\"attribute6 == '3'\"]\n",
      "    seed :  [\"attribute21 == '0'\"]\n",
      "    seed :  [\"attribute16 != '0'\"]\n",
      "    seed :  [\"attribute8 != '2'\"]\n",
      "    seed :  [\"attribute20 != '1'\"]\n",
      "    seed :  [\"attribute13 != '1'\"]\n",
      "    seed :  [\"attribute21 != '1'\"]\n",
      "    seed :  [\"attribute28 == '0'\"]\n",
      "    seed :  [\"attribute18 == '0'\"]\n",
      "    seed :  [\"attribute26 != '1'\"]\n",
      "    seed :  [\"attribute29 == '1'\"]\n",
      "    seed :  [\"attribute22 != '3'\"]\n",
      "    seed :  [\"attribute4 == '2'\"]\n",
      "    seed :  [\"attribute15 != '0'\"]\n",
      "    seed :  [\"attribute31 == '0'\"]\n",
      "    seed :  [\"attribute28 != '3'\"]\n",
      "    seed :  [\"attribute5 == '0'\"]\n",
      "    seed :  [\"attribute12 == '1'\"]\n",
      "    seed :  [\"attribute8 == '0'\"]\n",
      "    seed :  [\"attribute3 == '2'\"]\n",
      "    seed :  [\"attribute3 != '0'\"]\n",
      "    seed :  [\"attribute26 == '0'\"]\n",
      "    seed :  [\"attribute7 == '3'\"]\n",
      "    seed :  [\"attribute30 == '0'\"]\n",
      "    seed :  [\"attribute4 != '0'\"]\n",
      "    seed :  [\"attribute22 == '0'\"]\n",
      "    seed :  [\"attribute29 == '0'\"]\n",
      "    seed :  [\"attribute19 != '1'\"]\n",
      "    seed :  [\"attribute29 != '4'\"]\n",
      "    seed :  [\"attribute11 != '1'\"]\n",
      "    seed :  [\"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute15 == '1'\"]\n",
      "level :  2\n",
      "    seed :  [\"attribute6 != '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute7 != '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute29 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute17 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute35 != '2'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute23 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute22 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute3 == '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute33 == '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute22 != '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute1 != '6'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute13 == '2'\", \"attribute9 != '2'\"]\n",
      "    seed :  [\"attribute33 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute35 != '1'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute20 != '1'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute26 != '1'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute3 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute7 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute1 != '2'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute1 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute8 != '2'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute22 != '3'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute32 == '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute35 != '1'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute35 == '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute1 != '3'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute5 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute32 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute35 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute23 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute11 != '1'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute1 != '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute29 != '2'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute1 != '6'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute1 != '3'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute22 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute3 != '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute34 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute14 != '1'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute15 == '1'\", \"attribute9 != '2'\"]\n",
      "    seed :  [\"attribute6 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute33 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute18 != '2'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute7 != '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute17 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute35 != '1'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute18 != '2'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute4 != '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute1 != '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute32 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute4 != '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute1 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute6 != '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute20 != '1'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute26 != '1'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute31 == '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute22 != '3'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute30 == '0'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute31 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute5 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute8 != '2'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute30 == '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute5 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute17 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute1 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute29 != '2'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute4 != '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute11 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute3 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute34 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute13 != '1'\", \"attribute15 != '2'\"]\n",
      "    seed :  [\"attribute18 != '2'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute8 != '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute30 == '0'\", \"attribute14 == '0'\"]\n",
      "    seed :  [\"attribute35 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute32 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute14 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute32 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute1 != '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute29 != '2'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute11 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute3 != '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute17 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute34 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute18 != '2'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute20 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute26 != '1'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute22 != '3'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute31 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute22 != '3'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute30 == '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute15 != '0'\", \"attribute13 != '0'\"]\n",
      "    seed :  [\"attribute4 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute20 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute26 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute30 == '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute13 != '1'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute4 != '0'\", \"attribute15 == '1'\"]\n",
      "    seed :  [\"attribute15 != '0'\", \"attribute13 == '2'\"]\n",
      "    seed :  [\"attribute18 != '2'\", \"attribute15 == '1'\"]\n"
     ]
    }
   ],
   "source": [
    "df = dct_datasets['Soybean']['vanilla']\n",
    "test = EMM(100, 3, 100, [], df, 'target', ensure_diversity=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
